{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "00_Prepara_Dados.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RW5Azyfzunsl"
      },
      "outputs": [],
      "source": [
        "# !pip install sentence_transformers\n",
        "# !pip install keras_tuner\n",
        "# !pip install python-louvain\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "import csv\n",
        "import json\n",
        "import re\n",
        "import ast\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import NeighborhoodComponentsAnalysis\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,ConfusionMatrixDisplay,precision_score,recall_score,f1_score,pairwise_distances\n",
        "from sklearn.preprocessing import normalize\n",
        "from imblearn.under_sampling import AllKNN\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras_tuner as kt\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import networkx as nx\n",
        "import networkx.algorithms.community as nx_comm\n",
        "from community import community_louvain\n",
        "from ast import literal_eval\n",
        "np.set_printoptions(linewidth=25000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rawData = []\n",
        "\n",
        "with open(\"./booksummaries/booksummaries.txt\", 'r') as originalData:\n",
        "    data = csv.reader(originalData, dialect='excel-tab')\n",
        "    for row in data:\n",
        "        rawData.append(row)\n",
        "\n",
        "#print(rawData[245])\n",
        "#print(len(rawData))\n",
        "\n",
        "index = range(len(rawData))\n",
        "\n",
        "book_data = [[idx,r[0],r[2],r[3],r[4],r[5],r[6]] for idx, r in zip(index, rawData)]\n",
        "\n",
        "#book_data[0]\n",
        "\n",
        "df = pd.DataFrame(book_data,columns =['Index','ID','BookTitle','Author','PubDate','Genres_','Summary_'])\n",
        "\n",
        "#df.info()\n",
        "df.head(10)\n",
        "\n",
        "df = df.drop(df[df['Genres_'] == ''].index)\n",
        "df = df.drop(df[df['Summary_'] == ''].index)\n",
        "\n",
        "genres_data = []\n",
        "for g in df['Genres_']:\n",
        "    genres_data.append(list(json.loads(g).values()))\n",
        "\n",
        "df['Genres'] = genres_data\n",
        "\n",
        "genres_list = [i for l in df['Genres'] for i in l]\n",
        "genres_size = [len(l) for l in df['Genres']]\n",
        "genre_count = pd.value_counts(genres_list)\n",
        "\n",
        "df['Genres_Size'] = genres_size\n",
        "\n",
        "summary_size = [len(l.split(' ')) for l in df['Summary_']]\n",
        "summary_char = [re.search(r'[^\\w\\d\\s:.,!?]', l) for l in df['Summary_']]\n",
        "\n",
        "summary_text = []\n",
        "for s in df['Summary_']:\n",
        "    summary_text.append(re.sub(r'[^\\w\\d\\s:.,!?]',' ',s))\n",
        "\n",
        "df['Summary'] = summary_text\n",
        "df['Summary_Size'] = summary_size\n",
        "\n",
        "print(\"Gêneros distintos: \",len(genre_count),\"\\nContagem de palavras dos sumários, máx \", \\\n",
        "                             max(summary_size),\" e mín \",min(summary_size))\n",
        "\n",
        "selected_genres = ['Science Fiction','Novel','Fantasy',\"Children's literature\",\"Mystery\"]"
      ],
      "metadata": {
        "id": "6Ul7PFN8wErr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(genres_size,rwidth=0.85)\n",
        "plt.xlabel('Gêneros')\n",
        "plt.ylabel('Frequência')\n",
        "plt.title('Distribuição da quantidade de gêneros')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.hist(summary_size,np.linspace(0,1500,50),rwidth=0.85)\n",
        "plt.xlabel('Sumário')\n",
        "plt.ylabel('Frequência')\n",
        "plt.title('Distribuição do tamanho em palavras dos sumários')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QfJO3OkBwSMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_select = df.drop(df[df['Summary_Size'] > 400].index)\n",
        "df_select = df_select.drop(df_select[df_select['Summary_Size'] < 50].index)\n",
        "df_select = df_select.drop(df_select[df_select['Genres_Size'] > 5].index)\n",
        "df_select = df_select.drop(columns=['Index', 'Genres_', 'Summary_'])\n",
        "df_select = df_select.reset_index()\n",
        "\n",
        "df_genre = pd.DataFrame(df_select['Genres'].tolist(),columns=['G1', 'G2', 'G3', 'G4', 'G5'])\n",
        "\n",
        "df_select = pd.concat([df_select, df_genre], axis = 1)\n",
        "df_select.loc[~df_select['G1'].isin(selected_genres),'G1'] = 'None'\n",
        "df_select.loc[~df_select['G2'].isin(selected_genres),'G2'] = 'None'\n",
        "df_select.loc[~df_select['G3'].isin(selected_genres),'G3'] = 'None'\n",
        "df_select.loc[~df_select['G4'].isin(selected_genres),'G4'] = 'None'\n",
        "df_select.loc[~df_select['G5'].isin(selected_genres),'G5'] = 'None'\n",
        "\n",
        "df_ready = df_select[df_select[['G1','G2','G3','G4','G5']].isin(selected_genres).any(axis = 1)].copy()\n",
        "\n",
        "def arruma(x):\n",
        "    if x['G4'] == 'None':\n",
        "        x['G4'] = x['G5']\n",
        "        x['G5'] = 'None'\n",
        "    if x['G3'] == 'None':\n",
        "        x['G3'] = x['G4']\n",
        "        x['G4'] = x['G5']\n",
        "        x['G5'] = 'None'\n",
        "    if x['G2'] == 'None':\n",
        "        x['G2'] = x['G3']\n",
        "        x['G3'] = x['G4']\n",
        "        x['G4'] = x['G5']\n",
        "        x['G5'] = 'None'\n",
        "    if x['G1'] == 'None':\n",
        "        x['G1'] = x['G2']\n",
        "        x['G2'] = x['G3']\n",
        "        x['G3'] = x['G4']\n",
        "        x['G4'] = x['G5']\n",
        "        x['G5'] = 'None'\n",
        "    return x\n",
        "\n",
        "df_ready = df_ready.apply(lambda x: arruma(x), axis=1)\n",
        "df_ready['Genres_Class_Size'] = df_ready[df_ready[['G1','G2','G3','G4','G5']].isin(selected_genres)].count(axis=1)\n",
        "\n",
        "\n",
        "def numera(genres):\n",
        "    resp = []\n",
        "    for x in genres:\n",
        "        if x in selected_genres:\n",
        "            resp.append(selected_genres.index(x))\n",
        "    return resp\n",
        "\n",
        "df_ready['Genre_Class'] = df_ready[['G1','G2','G3','G4','G5']].apply(lambda x: numera(x), axis=1)\n",
        "\n",
        "\n",
        "\n",
        "plt.hist(df_ready['Genres_Class_Size'],[0.5,1.5,2.5,3.5,4.5,5.5],rwidth=0.85)\n",
        "plt.xlabel('Gêneros')\n",
        "plt.ylabel('Frequência')\n",
        "plt.title('Distribuição da quantidade de gêneros')\n",
        "plt.show()\n",
        "\n",
        "df_ready.info()"
      ],
      "metadata": {
        "id": "yswYSMeTwV4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ready_1g = df_ready[df_ready['Genres_Class_Size'] == 1].copy()\n",
        "df_ready_ag = df_ready[df_ready['Genres_Class_Size'] > 1].copy()\n",
        "\n",
        "df_ready_1g.info()\n",
        "df_ready_ag.info()"
      ],
      "metadata": {
        "id": "9Is_b_fkwcUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(df_ready['Genres_Size'],[0.5,1.5,2.5,3.5,4.5,5.5],rwidth=0.85)\n",
        "plt.xlabel('Gêneros')\n",
        "plt.ylabel('Frequência')\n",
        "plt.title('Distribuição da quantidade de gêneros')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.hist(df_ready['Summary_Size'],np.linspace(50,450,20),rwidth=0.85)\n",
        "plt.xlabel('Sumário')\n",
        "plt.ylabel('Frequência')\n",
        "plt.title('Distribuição do tamanho em palavras dos sumários')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Sr7NIjYoweJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = train_test_split(df_ready_1g, test_size=0.3, random_state=99)\n",
        "\n",
        "df_train = df_train.copy()\n",
        "df_test = df_test.copy()\n",
        "\n",
        "df_train.to_csv('/content/drive/MyDrive/TCC/df_train.txt')\n",
        "df_test.to_csv('/content/drive/MyDrive/TCC/df_test.txt')\n",
        "\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "bRBYexBdwgxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('/content/drive/MyDrive/TCC/finetune-test')\n",
        "model.max_seq_length = 512\n",
        "print(\"Max Sequence Length:\", model.max_seq_length)\n",
        "\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/TCC/df_train.txt')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/TCC/df_test.txt')\n",
        "\n",
        "df_train = df_train.drop(columns=['Embedding'])\n",
        "df_test = df_test.drop(columns=['Embedding'])\n",
        "\n",
        "def embedding(x):\n",
        "    return model.encode(x)\n",
        "    \n",
        "df_train['Embedding'] = df_train['Summary'].apply(lambda x: embedding(x))\n",
        "\n",
        "df_train.to_csv('/content/drive/MyDrive/TCC/df_train_new.txt')\n",
        "\n",
        "\n",
        "df_test['Embedding'] = df_test['Summary'].apply(lambda x: embedding(x))\n",
        "\n",
        "df_test.to_csv('/content/drive/MyDrive/TCC/df_test_new.txt')"
      ],
      "metadata": {
        "id": "iq50m32oxCeW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}